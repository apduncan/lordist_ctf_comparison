---
title: "LorDist benchmarks underestimate performance of established methods"
author: 
  - name: Anthony Duncan
    orcid: 0000-0002-3849-9527
    email: anthony.duncan@earlham.ac.uk
    affiliations:
        - ref: ei
        - ref: qib
  - name: Falk Hildebrand
    orcid: 0000-0002-0078-8948
    email: falk.hildebrand@quadram.ac.uk
    affiliations:
        - ref: qib
        - ref: ei
affiliations:
  - id: qib
    name: Quadram Institute
    address: Rosalind Franklin Road, Norwich Research Park
    city: Norwich
    country: United Kingdom
    postal-code: NR4 7UQ
  - id: ei
    name: Earlham Institute
    address: Norwich Research Park
    city: Norwich
    country: United Kingdom
    postal-code: NR4 7UZ
date: "November 11, 2025"
bibliography: refs.bib
filters:
  - acronyms
acronyms:
  insert_loa: false
  loa_title: "Abbreviations"
  keys:
    - shortname: CTF
      longname: compositional tensor factorization
    - shortname: PCoA
      longname: principal coordinates analysis
output:
  word_document:
    fig_caption: yes
  docx:
    toc: true
    reference-doc: doc-styles.docx
---

## Abstract
LorDist is a recently published method for analysis of longitudinal microbiome
data.
Benchmarks presented in this showed that competing method Compositional Tensor
Factorisation was unable to distinguish between groups in simulated data.
We repeat these benchmarks and show contrary results, finding that Compositional
Tensor Factorisation can separate these groups up to 50% sparsity.

## Importance
Inaccurate benchmarks can lead data analysts to inappropriate choice between
methods.
We show that for low sparsity data Compositional Tensor Factorisaion 
is a suitable method for longitudinal analysis, and that the established
Bray-Curtis dissimilarity showed similar performance in this simulated data.

## Body
In their article published recently in Microbiology Spectrum, Qi et al.
[-@qi_lordist_2025] introduced LorDist as a method for analysis of longitudinal 
microbial data.
Simulated benchmarks in that article showed their method to work well up to
quite high levels of sparsity.

To demonstrate the superiority of the method LorDist was benchmarked against 
Compositional Tensor Factorisation \acr{CTF} [@martino_context-aware_2021].
The authors showed that PERMANOVA tests relying on \acr{CTF} outputs could
not detect differences between two simulated phenotypes (P values non
significant, F values remaining similar) with increasing simulated sparsity.
Wanting to establish these results were correct, we repeated all benchmarks 
exactly, but we find contrary results that we feel need further clarifications
for data scientists interested in these methods.

In our simulations, both \acr{CTF} and LorDist performed well, though with
LorDist being able to cope with higher level of sparsity (@fig-res).

```{r}
#| label: fig-res
#| echo: FALSE
#| fig-cap: >
#|  Ability to detect community differences of CTF and LorDist. Shown are F
#|  statistics (left) and P-values (right, 1000 permutations) of PERMANOVA
#|  tests. These tests used either LorDist or CTF distances, or mean between
#|  subject Bray-Curtis dissimilarities as inputs. These were calculated on
#|  1000 simulated microbial datasets, for which different levels of sparsity
#|  were generated by randomly setting a proportion of entries to 0. Points are
#|  median values, error bars show 10% and 90% quantiles, the dashed horizontal
#|  grey line is at P=0.05. CTF results were tested using both the pairwise
#|  sample distances (CTF - Sample Distances) and euclidean distances between
#|  subjects in the subject ordination (CTF - Subject Ordination).
knitr::include_graphics(
    here::here("results", "simulated", "combined_fval_pval.png")
)
```

\acr{CTF} provides distances between samples, as well as subject level
ordination. 
It was unclear to us from the method description which was used in the
PERMANOVA during benchmarking. Due to this, for \acr{CTF} we tested both between
sample distances, and Euclidean distance between subjects in the ordination,
and results are presented for both.

We tested an additional established method, using the mean Bray-Curtis
dissimilarity between samples from pairs of subjects, and found that we can
obtain similar PERMANOVA results (grey points, @fig-res).
\acr{PCoA} of mean Bray-Curtis at 70% sparsity shows a clear separation of
the simulated groups which poses little challenege to this established numerical
ecology method (@fig-pcoa A).
Similar \acr{PCoA} using LorDist shows a separation on axes 5 and 6, albeit
less visually clear (@fig-pcoa B).
We selected axes 5 and 6 as no separation was evident on the first two axes.
This mean Bray-Curtis approach would not provide the additional insights
from the fitted functions available from LorDist however.

```{r}
#| label: fig-pcoa
#| echo: FALSE
#| fig-cap: >
#|  \acr{PCoA} ordinations using (A) mean Bray-Curtis disimilarity between
#|  subjects and (B) LorDist distances. A separation is evident on the first
#|  axis of the Bray-Curtis ordination. No separation was evident on the first
#|  two axes of the LorDist ordination; we show axes 5 and 6 as they show
#|  significant differences (Wilcoxon test, p<0.05) between groups.
knitr::include_graphics(
    here::here("results", "simulated", "pcoa_compare.png")
)
```

It is our belief that we have accurately repeated the benchmarks as described
in Methods [@qi_lordist_2025], however as no code for benchmarking was given we
are inviting the authors to further clarify.

We do note that Fig 2A in the [@qi_lordist_2025], showing curves for the counts
of simulated taxa over time, does not match the functions given for the
three types of taxa.
Similarly, plotting the example data from the LorDist GitHub repository
does not show taxa with distributions matching the Methods description
or Figure 2A in Qi et al. [-@qi_lordist_2025]. 
Plots illustrating this are available in our benchmark repository.
However we do not believe this would strongly impact the benchmark results.

Our suspicion is that the seemingly poor performance of \acr{CTF} was due to
the \acr{CTF} implementation returning results with samples in a different
order to their input. A simple programming mistake by Qi et al. not re-ordering
results could lead to uniformly non-significant P values due to mismatched
ordering between distances and metadata. The \acr{CTF} distance in our tests
performs better than presented in Qi et al. [-@qi_lordist_2025] and data 
analysts should be aware of this.

Our analysis is limited to the benchmark data, and as such does not extend to
analysis of real datasets which may have taxa with quite different
distributions.

Results and code for our benchmarks is available on 
[GitHub](https://github.com/apduncan/lordist_ctf_comparison), along with a
Docker container image for replication.

\printacronyms

## References